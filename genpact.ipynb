{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DEEP LEARNING MODEL WITH TENSORFLOW AND KERAS**\n",
    "## **ABOUT THE DATA:**\n",
    "### About Food Demand Forecasting Challenge\n",
    "- Demand forecasting is a key component to every growing online business. Without proper demand forecasting processes in place, it can be nearly impossible to have the right amount of stock on hand at any given time. A food delivery service has to deal with a lot of perishable raw materials which makes it all the more important for such a company to accurately forecast daily and weekly demand.\n",
    " \n",
    "- Too much inventory in the warehouse means more risk of wastage, and not enough could lead to out-of-stocks â€” and push customers to seek solutions from your competitors. In this challenge, get a taste of demand forecasting challenge using a real dataset.\n",
    "\n",
    "### Problem Statement\n",
    "- Your client is a meal delivery company which operates in multiple cities. They have various fulfillment centers in these cities for dispatching meal orders to their customers. The client wants you to help these centers with demand forecasting for upcoming weeks so that these centers will plan the stock of raw materials accordingly.\n",
    "\n",
    "- The replenishment of majority of raw materials is done on weekly basis and since the raw material is perishable, the procurement planning is of utmost importance. Secondly, staffing of the centers is also one area wherein accurate demand forecasts are really helpful. Given the following information, the task is to predict the demand for the next 10 weeks (Weeks: 146-155) for the center-meal combinations in the test set:  \n",
    "\n",
    "- Historical data of demand for a product-center combination (Weeks: 1 to 145)\n",
    "    - Product(Meal) features such as category, sub-category, current price and discount\n",
    "    - Information for fulfillment center like center area, city information etc.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = 15,8\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as splt\n",
    "# for handling the outliers\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 IMPORTING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 FEATURE ENGINEERING\n",
    "- **2.1. CHANGING THE DATA TYPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('id,week,num_orders,checkout_price,base_price'.split(','),axis=1)\n",
    "Y = test.drop('id,week,checkout_price,base_price'.split(','),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(str)\n",
    "Y = Y.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.describe())\n",
    "# print(Y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['center_id,meal_id,emailer_for_promotion,homepage_featured'.split(',')] = X\n",
    "test['center_id,meal_id,emailer_for_promotion,homepage_featured'.split(',')] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2.2 CREATING DUMMY VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train\n",
    "for i in 'center_id,meal_id,emailer_for_promotion,homepage_featured'.split(','):\n",
    "    data = pd.get_dummies(dataset[i],drop_first=True)\n",
    "    dataset = pd.concat([dataset,data],axis=1)\n",
    "train = dataset\n",
    "train.drop('center_id,meal_id,emailer_for_promotion,homepage_featured'.split(','),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = test\n",
    "for i in 'center_id,meal_id,emailer_for_promotion,homepage_featured'.split(','):\n",
    "    data = pd.get_dummies(dataset[i],drop_first=True)\n",
    "    dataset = pd.concat([dataset,data],axis=1)\n",
    "test = dataset\n",
    "test.drop('center_id,meal_id,emailer_for_promotion,homepage_featured'.split(','),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 EXCLUDING THE OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train.drop(['id','week'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for handling the outliers\n",
    "# # from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# clf = IsolationForest(max_samples = 100, random_state = 42)\n",
    "# clf.fit(new_train)\n",
    "# y_noano = clf.predict(new_train)\n",
    "# y_noano = pd.DataFrame(y_noano, columns = ['Top'])\n",
    "# y_noano[y_noano['Top'] == 1].index.values\n",
    "\n",
    "# new_train = new_train.iloc[y_noano[y_noano['Top'] == 1].index.values]\n",
    "# new_train.reset_index(drop = True, inplace = True)\n",
    "# print(\"Number of Outliers:\", y_noano[y_noano['Top'] == -1].shape[0])\n",
    "# print(\"Number of rows without outliers:\", new_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 SEPARATING THE INDEPENDENT AND DEPENDENT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_train.drop('num_orders',axis=1)\n",
    "Y = new_train['num_orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = test.drop(['id','week'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 FEATURE SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X\n",
    "# fitting and transforming the X into feature scaling\n",
    "X = scale.fit_transform(X)\n",
    "# converting again into dataframe\n",
    "X = pd.DataFrame(X,columns=data.columns)\n",
    "data = new_test\n",
    "# fitting and transforming the test into feature scaling\n",
    "new_test = scale.transform(new_test)\n",
    "# converting again into dataframe\n",
    "new_test = pd.DataFrame(new_test,columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.head())\n",
    "# print(new_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 SPLITTING THE X DATA INTO TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = splt(X, Y, test_size=0.9781, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 SAMPLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=66,kernel_initializer='normal',\n",
    "                     activation='relu',input_dim=130))\n",
    "    regressor.add(Dense(units=66,kernel_initializer='normal',\n",
    "                     activation='relu'))\n",
    "    regressor.add(Dense(units=66,kernel_initializer='normal',\n",
    "                     activation='relu'))\n",
    "    regressor.add(Dense(units=66,kernel_initializer='normal',\n",
    "                     activation='relu'))\n",
    "    regressor.add(Dense(units=66,kernel_initializer='normal',\n",
    "                     activation='relu'))\n",
    "    regressor.add(Dense(units=1,kernel_initializer='normal',\n",
    "                     activation='relu'))\n",
    "    regressor.compile(optimizer=Adadelta(),loss='mean_squared_logarithmic_error')\n",
    "    return regressor\n",
    "regressor = KerasRegressor(build_fn= build_regressor,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 456548 samples\n",
      "Epoch 1/100\n",
      "456548/456548 [==============================] - 326s 714us/sample - loss: 3.6188\n",
      "Epoch 2/100\n",
      "456548/456548 [==============================] - 281s 615us/sample - loss: 1.2137\n",
      "Epoch 3/100\n",
      "456548/456548 [==============================] - 281s 616us/sample - loss: 1.0186\n",
      "Epoch 4/100\n",
      "456548/456548 [==============================] - 281s 616us/sample - loss: 0.8317\n",
      "Epoch 5/100\n",
      "456548/456548 [==============================] - 281s 615us/sample - loss: 0.7031\n",
      "Epoch 6/100\n",
      "456548/456548 [==============================] - 291s 638us/sample - loss: 0.6234\n",
      "Epoch 7/100\n",
      "456548/456548 [==============================] - 334s 732us/sample - loss: 0.5713\n",
      "Epoch 8/100\n",
      "456548/456548 [==============================] - 283s 619us/sample - loss: 0.5375\n",
      "Epoch 9/100\n",
      "456548/456548 [==============================] - 279s 610us/sample - loss: 0.5152\n",
      "Epoch 10/100\n",
      "456548/456548 [==============================] - 285s 625us/sample - loss: 0.4997\n",
      "Epoch 11/100\n",
      "456548/456548 [==============================] - 285s 625us/sample - loss: 0.4881\n",
      "Epoch 12/100\n",
      "456548/456548 [==============================] - 297s 651us/sample - loss: 0.4790\n",
      "Epoch 13/100\n",
      "456548/456548 [==============================] - 286s 626us/sample - loss: 0.4714\n",
      "Epoch 14/100\n",
      "456548/456548 [==============================] - 295s 647us/sample - loss: 0.4648\n",
      "Epoch 15/100\n",
      "456548/456548 [==============================] - 361s 791us/sample - loss: 0.4590\n",
      "Epoch 16/100\n",
      "456548/456548 [==============================] - 287s 629us/sample - loss: 0.4538\n",
      "Epoch 17/100\n",
      "456548/456548 [==============================] - 287s 628us/sample - loss: 0.4491\n",
      "Epoch 18/100\n",
      "456548/456548 [==============================] - 291s 637us/sample - loss: 0.4447\n",
      "Epoch 19/100\n",
      "456548/456548 [==============================] - 289s 634us/sample - loss: 0.4406\n",
      "Epoch 20/100\n",
      "456548/456548 [==============================] - 292s 639us/sample - loss: 0.4367\n",
      "Epoch 21/100\n",
      "456548/456548 [==============================] - 401s 879us/sample - loss: 0.4331\n",
      "Epoch 22/100\n",
      "456548/456548 [==============================] - 290s 636us/sample - loss: 0.4297\n",
      "Epoch 23/100\n",
      "456548/456548 [==============================] - 294s 645us/sample - loss: 0.4263\n",
      "Epoch 24/100\n",
      "456548/456548 [==============================] - 299s 655us/sample - loss: 0.4231\n",
      "Epoch 25/100\n",
      "456548/456548 [==============================] - 351s 768us/sample - loss: 0.4200\n",
      "Epoch 26/100\n",
      "456548/456548 [==============================] - 294s 644us/sample - loss: 0.4170\n",
      "Epoch 27/100\n",
      "456548/456548 [==============================] - 293s 642us/sample - loss: 0.4140\n",
      "Epoch 28/100\n",
      "456548/456548 [==============================] - 297s 649us/sample - loss: 0.4112\n",
      "Epoch 29/100\n",
      "456548/456548 [==============================] - 298s 654us/sample - loss: 0.4084\n",
      "Epoch 30/100\n",
      "456548/456548 [==============================] - 297s 649us/sample - loss: 0.4057\n",
      "Epoch 31/100\n",
      "456548/456548 [==============================] - 296s 649us/sample - loss: 0.4031\n",
      "Epoch 32/100\n",
      "456548/456548 [==============================] - 309s 676us/sample - loss: 0.4005\n",
      "Epoch 33/100\n",
      "456548/456548 [==============================] - 298s 652us/sample - loss: 0.3980\n",
      "Epoch 34/100\n",
      "456548/456548 [==============================] - 344s 754us/sample - loss: 0.3955\n",
      "Epoch 35/100\n",
      "456548/456548 [==============================] - 350s 767us/sample - loss: 0.3932\n",
      "Epoch 36/100\n",
      "456548/456548 [==============================] - 321s 703us/sample - loss: 0.3908\n",
      "Epoch 37/100\n",
      "456548/456548 [==============================] - 305s 667us/sample - loss: 0.3885\n",
      "Epoch 38/100\n",
      "456548/456548 [==============================] - 299s 654us/sample - loss: 0.3862\n",
      "Epoch 39/100\n",
      "456548/456548 [==============================] - 300s 656us/sample - loss: 0.3839\n",
      "Epoch 40/100\n",
      "456548/456548 [==============================] - 302s 661us/sample - loss: 0.3817\n",
      "Epoch 41/100\n",
      "456548/456548 [==============================] - 310s 678us/sample - loss: 0.3795\n",
      "Epoch 42/100\n",
      "456548/456548 [==============================] - 311s 681us/sample - loss: 0.3773\n",
      "Epoch 43/100\n",
      "456548/456548 [==============================] - 316s 692us/sample - loss: 0.3752\n",
      "Epoch 44/100\n",
      "456548/456548 [==============================] - 766s 2ms/sample - loss: 0.3731\n",
      "Epoch 45/100\n",
      "456548/456548 [==============================] - 771s 2ms/sample - loss: 0.3711\n",
      "Epoch 46/100\n",
      "456548/456548 [==============================] - 642s 1ms/sample - loss: 0.3691\n",
      "Epoch 47/100\n",
      "456548/456548 [==============================] - 303s 664us/sample - loss: 0.3671\n",
      "Epoch 48/100\n",
      "456548/456548 [==============================] - 304s 666us/sample - loss: 0.3651\n",
      "Epoch 49/100\n",
      "456548/456548 [==============================] - 306s 671us/sample - loss: 0.3632\n",
      "Epoch 50/100\n",
      "456548/456548 [==============================] - 324s 710us/sample - loss: 0.3613\n",
      "Epoch 51/100\n",
      "456548/456548 [==============================] - 307s 672us/sample - loss: 0.3595\n",
      "Epoch 52/100\n",
      "456548/456548 [==============================] - 347s 760us/sample - loss: 0.3577\n",
      "Epoch 53/100\n",
      "456548/456548 [==============================] - 347s 759us/sample - loss: 0.3559\n",
      "Epoch 54/100\n",
      "456548/456548 [==============================] - 346s 758us/sample - loss: 0.3541\n",
      "Epoch 55/100\n",
      "456548/456548 [==============================] - 356s 779us/sample - loss: 0.3523\n",
      "Epoch 56/100\n",
      "456548/456548 [==============================] - 354s 776us/sample - loss: 0.3506\n",
      "Epoch 57/100\n",
      "456548/456548 [==============================] - 352s 770us/sample - loss: 0.3489\n",
      "Epoch 58/100\n",
      "456548/456548 [==============================] - 355s 777us/sample - loss: 0.3473\n",
      "Epoch 59/100\n",
      "456548/456548 [==============================] - 349s 764us/sample - loss: 0.3457\n",
      "Epoch 60/100\n",
      "456548/456548 [==============================] - 353s 772us/sample - loss: 0.3441\n",
      "Epoch 61/100\n",
      "456548/456548 [==============================] - 355s 777us/sample - loss: 0.3425\n",
      "Epoch 62/100\n",
      "456548/456548 [==============================] - 269s 590us/sample - loss: 0.3410\n",
      "Epoch 63/100\n",
      "456548/456548 [==============================] - 268s 588us/sample - loss: 0.3395\n",
      "Epoch 64/100\n",
      "456548/456548 [==============================] - 280s 614us/sample - loss: 0.3380\n",
      "Epoch 65/100\n",
      "456548/456548 [==============================] - 270s 591us/sample - loss: 0.3366\n",
      "Epoch 66/100\n",
      "456548/456548 [==============================] - 275s 602us/sample - loss: 0.3352\n",
      "Epoch 67/100\n",
      "456548/456548 [==============================] - 268s 587us/sample - loss: 0.3338\n",
      "Epoch 68/100\n",
      "456548/456548 [==============================] - 268s 587us/sample - loss: 0.3325\n",
      "Epoch 69/100\n",
      "456548/456548 [==============================] - 269s 589us/sample - loss: 0.3312\n",
      "Epoch 70/100\n",
      "456548/456548 [==============================] - 269s 589us/sample - loss: 0.3299\n",
      "Epoch 71/100\n",
      "456548/456548 [==============================] - 271s 593us/sample - loss: 0.3287\n",
      "Epoch 72/100\n",
      "456548/456548 [==============================] - 301s 659us/sample - loss: 0.3275\n",
      "Epoch 73/100\n",
      "456548/456548 [==============================] - 309s 676us/sample - loss: 0.3263\n",
      "Epoch 74/100\n",
      "456548/456548 [==============================] - 268s 587us/sample - loss: 0.3251\n",
      "Epoch 75/100\n",
      "456548/456548 [==============================] - 269s 589us/sample - loss: 0.3240\n",
      "Epoch 76/100\n",
      "456548/456548 [==============================] - 268s 587us/sample - loss: 0.3229\n",
      "Epoch 77/100\n",
      "456548/456548 [==============================] - 270s 591us/sample - loss: 0.3219\n",
      "Epoch 78/100\n",
      "456548/456548 [==============================] - 288s 630us/sample - loss: 0.3208\n",
      "Epoch 79/100\n",
      "456548/456548 [==============================] - 276s 605us/sample - loss: 0.3198\n",
      "Epoch 80/100\n",
      "456548/456548 [==============================] - 335s 733us/sample - loss: 0.3188\n",
      "Epoch 81/100\n",
      "456548/456548 [==============================] - 268s 587us/sample - loss: 0.3178\n",
      "Epoch 82/100\n",
      "456548/456548 [==============================] - 268s 587us/sample - loss: 0.3168\n",
      "Epoch 83/100\n",
      "456548/456548 [==============================] - 283s 619us/sample - loss: 0.3159\n",
      "Epoch 84/100\n",
      "456548/456548 [==============================] - 269s 589us/sample - loss: 0.3150\n",
      "Epoch 85/100\n",
      "456548/456548 [==============================] - 307s 673us/sample - loss: 0.3141\n",
      "Epoch 86/100\n",
      "456548/456548 [==============================] - 305s 669us/sample - loss: 0.3132\n",
      "Epoch 87/100\n",
      "456548/456548 [==============================] - 309s 676us/sample - loss: 0.3124\n",
      "Epoch 88/100\n",
      "456548/456548 [==============================] - 310s 680us/sample - loss: 0.3116\n",
      "Epoch 89/100\n",
      "456548/456548 [==============================] - 308s 674us/sample - loss: 0.3108\n",
      "Epoch 90/100\n",
      "456548/456548 [==============================] - 310s 679us/sample - loss: 0.3100\n",
      "Epoch 91/100\n",
      "456548/456548 [==============================] - 314s 687us/sample - loss: 0.3092\n",
      "Epoch 92/100\n",
      "456548/456548 [==============================] - 319s 699us/sample - loss: 0.3085\n",
      "Epoch 93/100\n",
      "456548/456548 [==============================] - 273s 598us/sample - loss: 0.3078\n",
      "Epoch 94/100\n",
      "456548/456548 [==============================] - 265s 580us/sample - loss: 0.3071\n",
      "Epoch 95/100\n",
      "456548/456548 [==============================] - 272s 595us/sample - loss: 0.3064\n",
      "Epoch 96/100\n",
      "456548/456548 [==============================] - 265s 581us/sample - loss: 0.3057\n",
      "Epoch 97/100\n",
      "456548/456548 [==============================] - 274s 600us/sample - loss: 0.3051\n",
      "Epoch 98/100\n",
      "456548/456548 [==============================] - 275s 602us/sample - loss: 0.3044\n",
      "Epoch 99/100\n",
      "456548/456548 [==============================] - 265s 581us/sample - loss: 0.3038\n",
      "Epoch 100/100\n",
      "456548/456548 [==============================] - 501s 1ms/sample - loss: 0.3032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efcea4dd0d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x=X,y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 9998 samples\n",
      "Epoch 1/100\n",
      "9998/9998 [==============================] - 16s 2ms/sample - loss: 25.2349\n",
      "Epoch 2/100\n",
      "9998/9998 [==============================] - 13s 1ms/sample - loss: 25.0808\n",
      "Epoch 3/100\n",
      "9998/9998 [==============================] - 13s 1ms/sample - loss: 24.3701\n",
      "Epoch 4/100\n",
      "9998/9998 [==============================] - 13s 1ms/sample - loss: 17.7069\n",
      "Epoch 5/100\n",
      "9998/9998 [==============================] - 14s 1ms/sample - loss: 6.7432\n",
      "Epoch 6/100\n",
      "9998/9998 [==============================] - 13s 1ms/sample - loss: 3.3871\n",
      "Epoch 7/100\n",
      "9998/9998 [==============================] - 14s 1ms/sample - loss: 2.4505\n",
      "Epoch 8/100\n",
      "9998/9998 [==============================] - 9s 881us/sample - loss: 2.1045\n",
      "Epoch 9/100\n",
      "9998/9998 [==============================] - 7s 676us/sample - loss: 1.9350\n",
      "Epoch 10/100\n",
      "9998/9998 [==============================] - 6s 620us/sample - loss: 1.8264\n",
      "Epoch 11/100\n",
      "9998/9998 [==============================] - 7s 652us/sample - loss: 1.7448\n",
      "Epoch 12/100\n",
      "9998/9998 [==============================] - 6s 647us/sample - loss: 1.6774\n",
      "Epoch 13/100\n",
      "9998/9998 [==============================] - 6s 624us/sample - loss: 1.6227\n",
      "Epoch 14/100\n",
      "9998/9998 [==============================] - 6s 640us/sample - loss: 1.5762\n",
      "Epoch 15/100\n",
      "9998/9998 [==============================] - 7s 651us/sample - loss: 1.5380\n",
      "Epoch 16/100\n",
      "9998/9998 [==============================] - 6s 650us/sample - loss: 1.5056\n",
      "Epoch 17/100\n",
      "9998/9998 [==============================] - 7s 665us/sample - loss: 1.4781\n",
      "Epoch 18/100\n",
      "9998/9998 [==============================] - 6s 649us/sample - loss: 1.4553\n",
      "Epoch 19/100\n",
      "9998/9998 [==============================] - 7s 661us/sample - loss: 1.4368\n",
      "Epoch 20/100\n",
      "9998/9998 [==============================] - 7s 672us/sample - loss: 1.4211\n",
      "Epoch 21/100\n",
      "9998/9998 [==============================] - 7s 660us/sample - loss: 1.4078\n",
      "Epoch 22/100\n",
      "9998/9998 [==============================] - 7s 657us/sample - loss: 1.3963\n",
      "Epoch 23/100\n",
      "9998/9998 [==============================] - 7s 669us/sample - loss: 1.3864\n",
      "Epoch 24/100\n",
      "9998/9998 [==============================] - 6s 644us/sample - loss: 1.3775\n",
      "Epoch 25/100\n",
      "9998/9998 [==============================] - 7s 665us/sample - loss: 1.3695\n",
      "Epoch 26/100\n",
      "9998/9998 [==============================] - 7s 655us/sample - loss: 1.3621\n",
      "Epoch 27/100\n",
      "9998/9998 [==============================] - 7s 666us/sample - loss: 1.3554\n",
      "Epoch 28/100\n",
      "9998/9998 [==============================] - 6s 644us/sample - loss: 1.3492\n",
      "Epoch 29/100\n",
      "9998/9998 [==============================] - 7s 696us/sample - loss: 1.3435\n",
      "Epoch 30/100\n",
      "9998/9998 [==============================] - 7s 693us/sample - loss: 1.3379\n",
      "Epoch 31/100\n",
      "9998/9998 [==============================] - 6s 648us/sample - loss: 1.3325\n",
      "Epoch 32/100\n",
      "9998/9998 [==============================] - 7s 679us/sample - loss: 1.3273\n",
      "Epoch 33/100\n",
      "9998/9998 [==============================] - 6s 644us/sample - loss: 1.3223\n",
      "Epoch 34/100\n",
      "9998/9998 [==============================] - 7s 724us/sample - loss: 1.3173\n",
      "Epoch 35/100\n",
      "9998/9998 [==============================] - 7s 691us/sample - loss: 1.3125\n",
      "Epoch 36/100\n",
      "9998/9998 [==============================] - 7s 698us/sample - loss: 1.3077\n",
      "Epoch 37/100\n",
      "9998/9998 [==============================] - 7s 664us/sample - loss: 1.3029\n",
      "Epoch 38/100\n",
      "9998/9998 [==============================] - 7s 673us/sample - loss: 1.2982\n",
      "Epoch 39/100\n",
      "9998/9998 [==============================] - 7s 667us/sample - loss: 1.2936\n",
      "Epoch 40/100\n",
      "9998/9998 [==============================] - 7s 688us/sample - loss: 1.2889\n",
      "Epoch 41/100\n",
      "9998/9998 [==============================] - 14s 1ms/sample - loss: 1.2844\n",
      "Epoch 42/100\n",
      "9998/9998 [==============================] - 13s 1ms/sample - loss: 1.2799\n",
      "Epoch 43/100\n",
      "9998/9998 [==============================] - 7s 704us/sample - loss: 1.2754\n",
      "Epoch 44/100\n",
      "9998/9998 [==============================] - 7s 697us/sample - loss: 1.2709\n",
      "Epoch 45/100\n",
      "9998/9998 [==============================] - 7s 722us/sample - loss: 1.2664\n",
      "Epoch 46/100\n",
      "9998/9998 [==============================] - 7s 714us/sample - loss: 1.2619\n",
      "Epoch 47/100\n",
      "9998/9998 [==============================] - 7s 685us/sample - loss: 1.2575\n",
      "Epoch 48/100\n",
      "9998/9998 [==============================] - 7s 669us/sample - loss: 1.2531\n",
      "Epoch 49/100\n",
      "9998/9998 [==============================] - 7s 679us/sample - loss: 1.2488\n",
      "Epoch 50/100\n",
      "9998/9998 [==============================] - 7s 674us/sample - loss: 1.2444\n",
      "Epoch 51/100\n",
      "9998/9998 [==============================] - 7s 685us/sample - loss: 1.2400\n",
      "Epoch 52/100\n",
      "9998/9998 [==============================] - 6s 586us/sample - loss: 1.2357\n",
      "Epoch 53/100\n",
      "9998/9998 [==============================] - 6s 572us/sample - loss: 1.2314\n",
      "Epoch 54/100\n",
      "9998/9998 [==============================] - 6s 605us/sample - loss: 1.2271\n",
      "Epoch 55/100\n",
      "9998/9998 [==============================] - 6s 593us/sample - loss: 1.2229\n",
      "Epoch 56/100\n",
      "9998/9998 [==============================] - 6s 587us/sample - loss: 1.2186\n",
      "Epoch 57/100\n",
      "9998/9998 [==============================] - 6s 603us/sample - loss: 1.2143\n",
      "Epoch 58/100\n",
      "9998/9998 [==============================] - 6s 578us/sample - loss: 1.2101\n",
      "Epoch 59/100\n",
      "9998/9998 [==============================] - 6s 611us/sample - loss: 1.2058\n",
      "Epoch 60/100\n",
      "9998/9998 [==============================] - 6s 618us/sample - loss: 1.2016\n",
      "Epoch 61/100\n",
      "9998/9998 [==============================] - 6s 624us/sample - loss: 1.1973\n",
      "Epoch 62/100\n",
      "9998/9998 [==============================] - 6s 598us/sample - loss: 1.1931\n",
      "Epoch 63/100\n",
      "9998/9998 [==============================] - 6s 592us/sample - loss: 1.1889\n",
      "Epoch 64/100\n",
      "9998/9998 [==============================] - 6s 583us/sample - loss: 1.1847\n",
      "Epoch 65/100\n",
      "9998/9998 [==============================] - 6s 597us/sample - loss: 1.1805\n",
      "Epoch 66/100\n",
      "9998/9998 [==============================] - 6s 603us/sample - loss: 1.1763\n",
      "Epoch 67/100\n",
      "9998/9998 [==============================] - 6s 599us/sample - loss: 1.1721\n",
      "Epoch 68/100\n",
      "9998/9998 [==============================] - 6s 623us/sample - loss: 1.1679\n",
      "Epoch 69/100\n",
      "9998/9998 [==============================] - 6s 589us/sample - loss: 1.1637\n",
      "Epoch 70/100\n",
      "9998/9998 [==============================] - 6s 562us/sample - loss: 1.1596\n",
      "Epoch 71/100\n",
      "9998/9998 [==============================] - 6s 610us/sample - loss: 1.1554\n",
      "Epoch 72/100\n",
      "9998/9998 [==============================] - 6s 613us/sample - loss: 1.1512\n",
      "Epoch 73/100\n",
      "9998/9998 [==============================] - 6s 587us/sample - loss: 1.1470\n",
      "Epoch 74/100\n",
      "9998/9998 [==============================] - 6s 576us/sample - loss: 1.1428\n",
      "Epoch 75/100\n",
      "9998/9998 [==============================] - 6s 570us/sample - loss: 1.1387\n",
      "Epoch 76/100\n",
      "9998/9998 [==============================] - 6s 595us/sample - loss: 1.1345\n",
      "Epoch 77/100\n",
      "9998/9998 [==============================] - 6s 589us/sample - loss: 1.1303\n",
      "Epoch 78/100\n",
      "9998/9998 [==============================] - 6s 600us/sample - loss: 1.1262\n",
      "Epoch 79/100\n",
      "9998/9998 [==============================] - 6s 593us/sample - loss: 1.1220\n",
      "Epoch 80/100\n",
      "9998/9998 [==============================] - 6s 603us/sample - loss: 1.1178\n",
      "Epoch 81/100\n",
      "9998/9998 [==============================] - 6s 607us/sample - loss: 1.1136\n",
      "Epoch 82/100\n",
      "9998/9998 [==============================] - 6s 584us/sample - loss: 1.1094\n",
      "Epoch 83/100\n",
      "9998/9998 [==============================] - 6s 631us/sample - loss: 1.1052\n",
      "Epoch 84/100\n",
      "9998/9998 [==============================] - 6s 610us/sample - loss: 1.1010\n",
      "Epoch 85/100\n",
      "9998/9998 [==============================] - 6s 624us/sample - loss: 1.0969\n",
      "Epoch 86/100\n",
      "9998/9998 [==============================] - 6s 601us/sample - loss: 1.0927\n",
      "Epoch 87/100\n",
      "9998/9998 [==============================] - 6s 618us/sample - loss: 1.0885\n",
      "Epoch 88/100\n",
      "9998/9998 [==============================] - 6s 583us/sample - loss: 1.0844\n",
      "Epoch 89/100\n",
      "9998/9998 [==============================] - 6s 613us/sample - loss: 1.0802\n",
      "Epoch 90/100\n",
      "9998/9998 [==============================] - 6s 591us/sample - loss: 1.0760\n",
      "Epoch 91/100\n",
      "9998/9998 [==============================] - 6s 615us/sample - loss: 1.0718\n",
      "Epoch 92/100\n",
      "9998/9998 [==============================] - 6s 558us/sample - loss: 1.0676\n",
      "Epoch 93/100\n",
      "9998/9998 [==============================] - 6s 569us/sample - loss: 1.0634\n",
      "Epoch 94/100\n",
      "9998/9998 [==============================] - 6s 566us/sample - loss: 1.0592\n",
      "Epoch 95/100\n",
      "9998/9998 [==============================] - 6s 605us/sample - loss: 1.0551\n",
      "Epoch 96/100\n",
      "9998/9998 [==============================] - 6s 562us/sample - loss: 1.0508\n",
      "Epoch 97/100\n",
      "9998/9998 [==============================] - 6s 582us/sample - loss: 1.0467\n",
      "Epoch 98/100\n",
      "9998/9998 [==============================] - 5s 548us/sample - loss: 1.0424\n",
      "Epoch 99/100\n",
      "9998/9998 [==============================] - 6s 558us/sample - loss: 1.0382\n",
      "Epoch 100/100\n",
      "9998/9998 [==============================] - 6s 574us/sample - loss: 1.0341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f977a322310>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regressor.fit(x=X_train,y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'batch_size': [10,100],\n",
    "#              'epochs': [100,500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search = GridSearchCV(estimator=regressor,\n",
    "#                           param_grid=parameters,\n",
    "#                           cv=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search = grid_search.fit(X=X_train,y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch=100,epochs=200,genpact score=58\n",
    "msle = cross_val_score(estimator=regressor, X=X_train, y=Y_train, cv=8, n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2108303 , -1.09141175, -1.11844567, -1.14719059, -1.16087241,\n",
       "       -1.10070157, -1.05073974, -1.13713647])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch=10,epochs=100,genpact score=\n",
    "msle2 = cross_val_score(estimator=regressor, X=X_train, y=Y_train, cv=8, n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.08299447, -1.07596189, -1.111733  , -1.05212329, -1.10924443,\n",
       "       -1.09144832, -1.06011402, -1.11257951])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msle2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Week And Different Tuning get score 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "Y_pred = regressor.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190.6174 , 196.05923, 167.09648, ..., 161.66206, 126.94097,\n",
       "       153.99043], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id,num_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(Y_pred,columns=['num_orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'],submission],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32573 entries, 0 to 32572\n",
      "Data columns (total 2 columns):\n",
      "id            32573 non-null int64\n",
      "num_orders    32573 non-null float32\n",
      "dtypes: float32(1), int64(1)\n",
      "memory usage: 381.8 KB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.257300e+04</td>\n",
       "      <td>32573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.248476e+06</td>\n",
       "      <td>123.600601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.441580e+05</td>\n",
       "      <td>36.218822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000085e+06</td>\n",
       "      <td>44.302490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.123969e+06</td>\n",
       "      <td>94.348747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.247296e+06</td>\n",
       "      <td>120.853554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.372971e+06</td>\n",
       "      <td>148.965805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.499996e+06</td>\n",
       "      <td>243.347885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    num_orders\n",
       "count  3.257300e+04  32573.000000\n",
       "mean   1.248476e+06    123.600601\n",
       "std    1.441580e+05     36.218822\n",
       "min    1.000085e+06     44.302490\n",
       "25%    1.123969e+06     94.348747\n",
       "50%    1.247296e+06    120.853554\n",
       "75%    1.372971e+06    148.965805\n",
       "max    1.499996e+06    243.347885"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1028232</td>\n",
       "      <td>190.617401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1127204</td>\n",
       "      <td>196.059235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1212707</td>\n",
       "      <td>167.096481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082698</td>\n",
       "      <td>140.126144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400926</td>\n",
       "      <td>119.282150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  num_orders\n",
       "0  1028232  190.617401\n",
       "1  1127204  196.059235\n",
       "2  1212707  167.096481\n",
       "3  1082698  140.126144\n",
       "4  1400926  119.282150"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1028232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1127204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1212707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id\n",
       "0  1028232\n",
       "1  1127204\n",
       "2  1212707\n",
       "3  1082698\n",
       "4  1400926"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['id']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32573, 132)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32573, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Predition (Y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "Y_pred2 = regressor.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2 = pd.DataFrame(Y_pred2,columns=['num_orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2 = pd.concat([test['id'],submission2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.257300e+04</td>\n",
       "      <td>32573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.248476e+06</td>\n",
       "      <td>207.850876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.441580e+05</td>\n",
       "      <td>233.581116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000085e+06</td>\n",
       "      <td>3.809295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.123969e+06</td>\n",
       "      <td>51.215984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.247296e+06</td>\n",
       "      <td>123.923637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.372971e+06</td>\n",
       "      <td>277.776550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.499996e+06</td>\n",
       "      <td>1996.601929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    num_orders\n",
       "count  3.257300e+04  32573.000000\n",
       "mean   1.248476e+06    207.850876\n",
       "std    1.441580e+05    233.581116\n",
       "min    1.000085e+06      3.809295\n",
       "25%    1.123969e+06     51.215984\n",
       "50%    1.247296e+06    123.923637\n",
       "75%    1.372971e+06    277.776550\n",
       "max    1.499996e+06   1996.601929"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1028232</td>\n",
       "      <td>218.885559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1127204</td>\n",
       "      <td>184.395081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1212707</td>\n",
       "      <td>101.682968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082698</td>\n",
       "      <td>37.129036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400926</td>\n",
       "      <td>32.776661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  num_orders\n",
       "0  1028232  218.885559\n",
       "1  1127204  184.395081\n",
       "2  1212707  101.682968\n",
       "3  1082698   37.129036\n",
       "4  1400926   32.776661"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2.to_csv('submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Save And Reload Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SAVING THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My model name is regressor and I am using model.save function to the model\n",
    "# in HDF5 format.\n",
    "# regressor.model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RELOADING THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassigning the model after loading the models(model2,model3)\n",
    "model = load_model('model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **PREDICTION 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':list(test['id']),\n",
    "                           'num_orders':list(Y_pred.ravel())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1028232</td>\n",
       "      <td>259.886139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1127204</td>\n",
       "      <td>158.027649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1212707</td>\n",
       "      <td>137.175491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082698</td>\n",
       "      <td>26.660126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400926</td>\n",
       "      <td>32.790962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  num_orders\n",
       "0  1028232  259.886139\n",
       "1  1127204  158.027649\n",
       "2  1212707  137.175491\n",
       "3  1082698   26.660126\n",
       "4  1400926   32.790962"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **PREDICTION 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':list(test['id']),\n",
    "                           'num_orders':list(Y_pred.ravel())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission4.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
